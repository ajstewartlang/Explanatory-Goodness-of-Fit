---
title: "Analysis of Total Reading Times"
author: "Henrik Singmann"
output: 
  html_notebook:
    toc: yes
    toc_float: true
date: "`r format(Sys.time(), '%d %B, %Y')`"
---


```{r setup, results='hide', message=FALSE}
require(dplyr)
require(tidyr)
require(stringr)
require(ggplot2)
require(afex)
require(lattice) # for qqmath
require(gridExtra)
library(ggthemes)
theme_set(theme_minimal())

```

# Data Preparation

```{r}
data_in <- read.csv("TTs_plus_ratings.csv")
data_in$P.s <- factor(data_in$P.s)
data_in$Item <- factor(data_in$Item)
drp_r <- droplevels(data_in[data_in$Item != "9" ,])
nas <- is.na(drp_r$spillover) | is.na(drp_r$Consequent)
drp_r <- droplevels(drp_r[!nas,])

```

For the analysis we remove `r sum(nas)` trials with missing data in either spillover or Consequent. Then we transform all RTs from ms to s and calculate transformed versions using either `log` or the inverse transformation. We also z-transform the continuous `Accepts` variable.

```{r}
drp_r <- drp_r %>%
  mutate(
    antecedent = Antecedent/1000,
    log_ant = log(antecedent),
    inv_ant = 1/antecedent,
    consequent = Consequent/1000,
    log_con = log(consequent),
    inv_con = 1/consequent,
    spillover = spillover/1000,
    log_spill = log(spillover),
    inv_spill = 1/spillover,
    acc_z = (Accepts - mean(Accepts))/sd(Accepts),
    #conf_z = (Confident- mean(Confident))/sd(Confident),
    log_acc= log(Accepts))
```

We then plot the three versions of the DVs.

```{r}
dplot <- drp_r %>% 
  gather("key", "value",consequent:inv_spill, spillover) %>% 
  mutate(region = if_else(str_detect(key, "spill"), "spillover", "consequent"), 
         type = if_else(str_detect(key, "^log"), "log", 
                        if_else(str_detect(key, "^inv"), "inverse", "original")))

ggplot(data = dplot) +
  geom_histogram(mapping = aes(x = value), bins = 100) + 
  facet_grid(region ~ type)
```

As can be seen, the log transformation helps quite a bit in achieving approximate normality for both consequent and spillover. However, both DVs seems to have too fat tails. For the `spillover` variable the untransformed DV may work better. For the untransformed values there are quite a few DVs above 5 seconds (consequent = `r round(mean(drp_r$consequent > 5), 2)`, spillover = `r round(mean(drp_r$spillover > 5), 2)`), above 3 seconds (consequent = `r round(mean(drp_r$consequent > 3), 2)`, spillover = `r round(mean(drp_r$spillover > 3), 2)`) or above 2.5 seconds (consequent = `r round(mean(drp_r$consequent > 2.5), 2)`, spillover = `r round(mean(drp_r$spillover > 2.5), 2)`).

# Descriptive Plots

```{r, fig.width=8, fig.height=4}
drd_a2 <- drp_r %>% 
  group_by(P.s, Fit) %>% 
  summarise(log_spill = mean(log_spill))

drp_r$Fit2 <- jitter(as.numeric(drp_r$Fit))
drd_a2$Fit2 <- jitter(as.numeric(drd_a2$Fit))

pres_rp_a <- ggplot(data = drp_r, mapping = aes(x = Fit, y = log_spill)) +
  geom_boxplot(outlier.color =  NA) +
  geom_line(data = drd_a2, aes(x=Fit2, y=log_spill, group = P.s), alpha = 0.5) +
  geom_point(data = drd_a2, aes(x=Fit2, y=log_spill, group = P.s), alpha = 0.5) +
  stat_summary(fun.y = "mean", colour = "red", size = 2, geom = "point")

pres_rp_b <- ggplot(data = drp_r, mapping = aes(x = log_acc, y = log_spill)) +
  geom_point(alpha = 0.5)

pres_rp_c <- ggplot(data = drp_r, mapping = aes(x = acc_z, y = log_spill)) +
  geom_point(alpha = 0.5) 

grid.arrange(pres_rp_a, pres_rp_b, pres_rp_c, ncol = 3)
```

# Consequent

Note that the maximal model for models including `Fit` have random slopes for `Fit` for both random effects grouping factors (i.e., participant `P.s` and `Item`). For models including the continuous fit measure `Accepts` we have by-participant random slopes for `Accepts`, but by-item random slopes for `Fit` (as `Accepts` has only two different values for each `Item`,  using the binary `Fit` variable seems more reasonable.)

## With Fit (log-transformed RTs)

```{r}
m_fp_con_1 <- mixed(log_con ~ Fit + (Fit|P.s) + (Fit| Item), drp_r, progress = FALSE)
summary(m_fp_con_1)
```

Although the correlations are not extreme, we try by removing them.

```{r}
m_fp_con_2 <- mixed(log_con ~ Fit + (Fit||P.s) + (Fit|| Item), drp_r, expand_re = TRUE, progress = FALSE)
summary(m_fp_con_2)
```

This does not seem to be justified when looking at likelihood-ratio tests.

```{r}
anova(m_fp_con_1, m_fp_con_2)
```

However, the QQ-plot of both models shows some departure from normality for both short RTs and somewhat long RTs. One RT for participant 10 departs particularly strongly. Significant outliers (i.e., observations with absolute standardized/normalized residuals greater than the .995 quantile of the standard normal distribution) are identified by the number of the participant providing this response.

```{r, fig.width=8, fig.height=4}
qqp_m1 <- qqmath(m_fp_con_1$full_model, id = 0.01, idLabels = as.character(drp_r$P.s))
qqp_m2 <- qqmath(m_fp_con_2$full_model, id = 0.01, idLabels = as.character(drp_r$P.s))
grid.arrange(qqp_m1, qqp_m2, ncol = 2)
```

The effect of `Fit` is not significant for both models, but approaches significance.

```{r}
nice(m_fp_con_1)
nice(m_fp_con_2)
```

## With Fit (untransformed RTs)

```{r}
m_con_u_1 <- mixed(consequent ~ Fit + (Fit|P.s) + (Fit| Item), drp_r, progress = FALSE)
summary(m_con_u_1)
```

Due to the extreme correlations between the by-participant and by-item intercept and slopes we refit the model without the correlations.

```{r}
m_con_u_2 <- mixed(consequent ~ Fit + (Fit||P.s) + (Fit|| Item), drp_r, 
                   progress = FALSE, expand_re = TRUE)
summary(m_con_u_2)
```

Now the `Fit` random slopes show no variability so we consequently refit the model without that parameter.

```{r}
m_con_u_3 <- mixed(consequent ~ Fit + (1|P.s) + (1| Item), drp_r, progress = FALSE)
summary(m_con_u_3)
```

This model seems reasonable and only provides a minimally worse account than the first model.

```{r}
anova(m_con_u_1, m_con_u_2, m_con_u_3)
```

However, the QQ-plot now shows the perhaps expected misfit for long RTs.

```{r, fig.width=8, fig.height=4}
qqp_m1 <- qqmath(m_con_u_1$full_model, id = 0.01, idLabels = as.character(drp_r$P.s))
qqp_m2 <- qqmath(m_con_u_3$full_model, id = 0.01, idLabels = as.character(drp_r$P.s))
grid.arrange(qqp_m1, qqp_m2, ncol = 2)
```


Again, the effect of `Fit` is not significant.

```{r}
nice(m_con_u_1)
nice(m_con_u_3)
```

## With Fit (log-transformed RTs), Reduced Sample

We refit the logged RTs with a reduced model for which we remove one response of ID 10.

```{r}
outl <- (drp_r$P.s == "10" & drp_r$consequent > 4) #|
  #(drp_r$P.s == "16" & (drp_r$log_con < -1 | drp_r$log_con > 1) )
drp_r_1 <- drp_r[!outl,]
```


```{r}
m_fp_con_1b <- mixed(log_con ~ Fit + (Fit|P.s) + (Fit| Item), drp_r_1, progress = FALSE)
summary(m_fp_con_1b)
```

Although the correlations are not extreme, we try by removing them.

```{r}
m_fp_con_2b <- mixed(log_con ~ Fit + (Fit||P.s) + (Fit|| Item), drp_r_1, progress = FALSE, expand_re = TRUE)
summary(m_fp_con_2b)
```

This does not seem to be justified when looking at likelihood-ratio tests.

```{r}
anova(m_fp_con_1b, m_fp_con_2b)
```

However, the QQ-plot of both models shows some departure from normality for both short RTs and somewhat long RTs. One RT for participant 10 departs particularly strongly. Significant outliers (i.e., observations with absolute standardized/normalized residuals greater than the .995 quantile of the standard normal distribution) are identified by the number of the participant providing this response.

```{r, fig.width=8, fig.height=4}
qqp_m1 <- qqmath(m_fp_con_1b$full_model, id = 0.01, idLabels = as.character(drp_r_1$P.s))
qqp_m2 <- qqmath(m_fp_con_2b$full_model, id = 0.01, idLabels = as.character(drp_r_1$P.s))
grid.arrange(qqp_m1, qqp_m2, ncol = 2)
```

The effect of `Fit` is not significant for both models, but approaches significance.

```{r}
nice(m_fp_con_1b)
nice(m_fp_con_2b)
```


## With Accepts (log-transformed RT and Accepts)

```{r}
m_fp_con_11 <- mixed(log_con ~ log_acc + (log_acc|P.s) + (Fit| Item), drp_r, progress = FALSE)
summary(m_fp_con_11)
```

As for the binary variable we see an extreme correlation between the random-effects parameters for the by-participant random effect.


```{r}
m_fp_con_12 <- mixed(log_con ~ log_acc + (log_acc||P.s) + (Fit|Item), drp_r, expand_re = TRUE, progress = FALSE)
summary(m_fp_con_12)
```

The reduced model seems to provide the better account.

```{r}
anova(m_fp_con_11, m_fp_con_12)
```

However, we again see some departure from normality.

```{r, fig.width=8, fig.height=4}
qqp_11 <- qqmath(m_fp_con_11$full_model, id = 0.01, idLabels = as.character(drp_r$P.s))
qqp_12 <- qqmath(m_fp_con_12$full_model, id = 0.01, idLabels = as.character(drp_r$P.s))
grid.arrange(qqp_11, qqp_12, ncol = 2)
```

Again, neither model shows a significant effect of `log_acc`.

```{r}
nice(m_fp_con_11)
nice(m_fp_con_12)
```

## With Accepts (log-transformed RTs)

```{r}
m_fp_con_21 <- mixed(log_con ~ acc_z + (acc_z|P.s) + (Fit| Item), drp_r, progress = FALSE)
summary(m_fp_con_21)
```

We remove the correlations among the by-participant random effects.

```{r}
m_fp_con_22 <- mixed(log_con ~ acc_z + (acc_z||P.s) + (Fit|Item), drp_r, expand_re = TRUE, progress = FALSE)
summary(m_fp_con_22)
```

We then also remove the by-participant random slopes.

```{r}
m_fp_con_23 <- mixed(log_con ~ acc_z + (1|P.s) + (Fit|Item), drp_r, 
                     expand_re = FALSE, progress = FALSE)
summary(m_fp_con_23)
```

```{r}
anova(m_fp_con_21, m_fp_con_22, m_fp_con_23)
```

There is some difference between the maximal and the final reduced model. However, both models again show the same problematic pattern in their QQ-plots for the same participants.

```{r, fig.width=8, fig.height=4}
qqp_21 <- qqmath(m_fp_con_21$full_model, id = 0.01, idLabels = as.character(drp_r$P.s))
qqp_22 <- qqmath(m_fp_con_23$full_model, id = 0.01, idLabels = as.character(drp_r$P.s))
grid.arrange(qqp_21, qqp_22, ncol = 2)
```

Furthermore, neither model shows a significant effect of `Accepts` (z-transformed to `acc_z`).

```{r}
nice(m_fp_con_21)
nice(m_fp_con_23)
```

## With Accepts (log-transformed RTs and reduced data set)

```{r}
m_con_ar_1 <- mixed(log_con ~ acc_z + (acc_z|P.s) + (Fit| Item), 
                           drp_r_1, progress = FALSE)
summary(m_con_ar_1)
```

We remove the correlations among the random effects.

```{r}
m_con_ar_2 <- mixed(log_con ~ acc_z + (acc_z||P.s) + (Fit | Item), 
                           drp_r_1, progress = FALSE, expand_re = TRUE)
summary(m_con_ar_2)
```

```{r}
m_con_ar_3 <- mixed(log_con ~ acc_z + (1|P.s) + (Fit | Item), 
                           drp_r_1, progress = FALSE, expand_re = FALSE)
summary(m_con_ar_3)
```

```{r}
anova(m_con_ar_1, m_con_ar_2, m_con_ar_3)
```

Despite the correlation estimate of 1/-1, there seems to be some value in it. The QQ-plots show a only mild violations.

```{r, fig.width=8, fig.height=4}
qqp_21 <- qqmath(m_con_ar_1$full_model, id = 0.01, idLabels = as.character(drp_r_1$P.s))
qqp_22 <- qqmath(m_con_ar_3$full_model, id = 0.01, idLabels = as.character(drp_r_1$P.s))
grid.arrange(qqp_21, qqp_22, ncol = 2)
```

Furthermore, neither model shows a significant effect of `Accepts` (z-transformed to `acc_z`).

```{r}
nice(m_con_ar_1)
nice(m_con_ar_3)
```

# Spillover

## With Fit (log-transformed RTs)

```{r}
m_fp_spill_f_1 <- mixed(log_spill ~ Fit + (Fit|P.s) + (Fit| Item), drp_r, progress = FALSE)
summary(m_fp_spill_f_1)
```

Due to the large correlation between the by-participants and by-item random-effects parameters we refit the model without the correlations.

```{r}
m_fp_spill_f_2 <- mixed(log_spill ~ Fit + (Fit||P.s) + (Fit||Item), drp_r, expand_re = TRUE, progress = FALSE)
summary(m_fp_spill_f_2)
```
Now both random slopes are estimated to be zero, we consequently refit the model without those parameters.

```{r}
m_fp_spill_f_3 <- mixed(log_spill ~ Fit + (1|P.s) + (1| Item), drp_r, progress = FALSE)
summary(m_fp_spill_f_3)
```

Again the final model appears to be the optimal model.

```{r}
anova(m_fp_spill_f_1, m_fp_spill_f_3)
```

The QQ-plot again shows a clear deviation from normality for fast responses.

```{r, fig.width=8, fig.height=4}
qqp_m1 <- qqmath(m_fp_spill_f_1$full_model, id = 0.01, idLabels = as.character(drp_r$P.s))
qqp_m2 <- qqmath(m_fp_spill_f_3$full_model, id = 0.01, idLabels = as.character(drp_r$P.s))
grid.arrange(qqp_m1, qqp_m2, ncol = 2)
```


The effect of `Fit` is not significant.

```{r}
nice(m_fp_spill_f_1)
nice(m_fp_spill_f_3)
```

## With Fit (log-transformed RTs and reduced data set)

We again reduce the data set by one observation with a fast RT for participant 16.

```{r}
out_spill <- (drp_r$P.s == "16" & drp_r$spillover < 1.0 ) 
drp_r_r2 <- drp_r[!out_spill,]
drp_r_r2$spilloverw <- as.vector(LambertW::Gaussianize(drp_r_r2$spillover, 
                                                        type = "h", method = "MLE"))
```


```{r}
m_fp_spill_fr_1 <- mixed(log_spill ~ Fit + (Fit|P.s) + (Fit| Item), drp_r_r2, progress = FALSE)
summary(m_fp_spill_fr_1)
```

Due to the large correlation between the by-participants and by-item random-effects parameters we refit the model without the correlations.

```{r}
m_fp_spill_fr_2 <- mixed(log_spill ~ Fit + (Fit||P.s) + (Fit|| Item), drp_r_r2, progress = FALSE, expand_re = TRUE)
summary(m_fp_spill_fr_2)
```
Now both random slopes are estimated to be virtually zero, we consequently refit the model without those parameters.

```{r}
m_fp_spill_fr_3 <- mixed(log_spill ~ Fit + (1|P.s) + (1| Item), drp_r_r2, progress = FALSE)
summary(m_fp_spill_fr_3)
```

Again the final model appears to be the optimal model.

```{r}
anova(m_fp_spill_fr_1, m_fp_spill_fr_2, m_fp_spill_fr_3)
```

The QQ-plot now only shows comparatively mild violations at the edges.

```{r, fig.width=8, fig.height=4}
qqp_m1 <- qqmath(m_fp_spill_fr_1$full_model, id = 0.01, idLabels = as.character(drp_r_r2$P.s))
qqp_m2 <- qqmath(m_fp_spill_fr_3$full_model, id = 0.01, idLabels = as.character(drp_r_r2$P.s))
grid.arrange(qqp_m1, qqp_m2, ncol = 2)
```


The effect of `Fit` remains not significant. This would also not change when using the Lambert transform RTs.

```{r}
nice(m_fp_spill_fr_1)
nice(m_fp_spill_fr_3)
```



## With Accepts (log-transformed RTs and Accepts)

```{r}
m_fp_spill_al_1 <- mixed(log_spill ~ log_acc + (log_acc|P.s) + (Fit| Item), 
                         drp_r, progress = FALSE)
summary(m_fp_spill_al_1)
```

This model has correlations at the boundary of the parameter space. We refit the model without the correlations.

```{r}
m_fp_spill_al_2 <- mixed(log_spill ~ log_acc + (log_acc||P.s) + (Fit|| Item), 
                         drp_r, progress = FALSE, expand_re = TRUE)
summary(m_fp_spill_al_2)
```
The by-item random slope is zero hence we refit the model without it. 

```{r}
m_fp_spill_al_3 <- mixed(log_spill ~ log_acc + (log_acc||P.s) + (1| Item), 
                         drp_r, progress = FALSE, expand_re = TRUE)
summary(m_fp_spill_al_3)
```

Finally, because the correlation for the by-participant random effects was not 1 or -1 we finally add them again to the reduced model of the previous step.

```{r}
m_fp_spill_al_4 <- mixed(log_spill ~ log_acc + (log_acc|P.s) + (1| Item), 
                         drp_r, progress = FALSE, expand_re = TRUE)
summary(m_fp_spill_al_4)
```

Overall the best model appears to be the most reduced model 3.

```{r}
anova(m_fp_spill_al_1,m_fp_spill_al_2, m_fp_spill_al_3, m_fp_spill_al_4)
```

The QQ-plot of both models again shows some departure from normality for small and large RTs.

```{r, fig.width=8, fig.height=4}
qqp_m1 <- qqmath(m_fp_spill_al_1$full_model, id = 0.01, idLabels = as.character(drp_r$P.s))
qqp_m2 <- qqmath(m_fp_spill_al_3$full_model, id = 0.01, idLabels = as.character(drp_r$P.s))
grid.arrange(qqp_m1, qqp_m2, ncol = 2)
```


The effect of `log_acc` is not significant.

```{r}
nice(m_fp_spill_al_1)
nice(m_fp_spill_al_3)
```

### With Accepts (log-transformed RTs)

```{r}
m_fp_spill_a_1 <- mixed(log_spill ~ acc_z + (acc_z|P.s) + (Fit| Item), drp_r, progress = FALSE)
summary(m_fp_spill_a_1)
```

Again we observe one large correlation between the by-item random-effects parameters and we refit the model without this correlation. We also remove the other correlation as it is virtually zero.

```{r}
m_fp_spill_a_2 <- mixed(log_spill ~ acc_z + (acc_z||P.s) + (Fit||Item), drp_r, expand_re = TRUE, progress = FALSE)
summary(m_fp_spill_a_2)
```
And the by-item random slope is now estimated at zero, we consequently refit the model without this parameters.

```{r}
m_fp_spill_a_3 <- mixed(log_spill ~ acc_z + (acc_z||P.s) + (1| Item), drp_r, expand_re = TRUE, progress = FALSE)
summary(m_fp_spill_a_3)
```

This model seems reasonable and only provides basically the same account as the first model.

```{r}
anova(m_fp_spill_a_1, m_fp_spill_a_3)
```

The QQ-plot of both models again shows considerable departarue from normality for small RTs.

```{r, fig.width=8, fig.height=4}
qqp_m1 <- qqmath(m_fp_spill_a_1$full_model, id = 0.01, idLabels = as.character(drp_r$P.s))
qqp_m2 <- qqmath(m_fp_spill_a_3$full_model, id = 0.01, idLabels = as.character(drp_r$P.s))
grid.arrange(qqp_m1, qqp_m2, ncol = 2)
```


The effect of `acc_z` is not significant.

```{r}
nice(m_fp_spill_a_1)
nice(m_fp_spill_a_3)
```

## With Accept (reduced data set)

Finally we again use the reduced data set.

```{r}
m_fp_spill_lambert_a_1 <- mixed(log_spill ~ acc_z + (acc_z|P.s) + (Fit| Item), drp_r_r2, progress = FALSE)
summary(m_fp_spill_lambert_a_1)
```

We again remove the correlations.

```{r}
m_fp_spill_lambert_a_2 <- mixed(log_spill ~ acc_z + (acc_z||P.s) + (Fit || Item), drp_r_r2, progress = FALSE, expand_re = TRUE)
summary(m_fp_spill_lambert_a_2)
```
Now the by-item random slope is estimated to be virtually zero, we consequently refit the model without this parameter.

```{r}
m_fp_spill_lambert_a_3 <- mixed(log_spill ~ acc_z + (acc_z||P.s) + (1| Item), drp_r_r2, progress = FALSE, expand_re = TRUE)
summary(m_fp_spill_lambert_a_3)
```

Again the final model appears to be the optimal model.

```{r}
anova(m_fp_spill_lambert_a_1, m_fp_spill_lambert_a_2, m_fp_spill_lambert_a_3)
```

The QQ-plot now still shows violations at the edges. 

```{r, fig.width=8, fig.height=4}
qqp_m1 <- qqmath(m_fp_spill_lambert_a_1$full_model, id = 0.01, idLabels = as.character(drp_r_r2$P.s))
qqp_m2 <- qqmath(m_fp_spill_lambert_a_3$full_model, id = 0.01, idLabels = as.character(drp_r_r2$P.s))
grid.arrange(qqp_m1, qqp_m2, ncol = 2)
```


The effect of `Fit` remains not significant.

```{r}
nice(m_fp_spill_lambert_a_1)
nice(m_fp_spill_lambert_a_3)
```


